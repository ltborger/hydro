# -*- coding: utf-8 -*-
"""RODEO_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15lWhlLkLtvrGfrkM3DVFzUz8et4kw1Mv

#RODEO Analysis

This notebook seeks to compare data and establish relationships between two datasets that delineate river features such as Width, Discharge (Q), and Power Density (Potential) at 26 rural villages across the state of Alaska.

Datasets:

1. RODEO Feature Collection of Alaska, which was produced by Ryan Riggs and published by the Official Journal of the International Environmental Modelling & Software Society in 2022.  

2. Alaska In-River Hydrokinetic Energy Resource Assessment done by Tom Ravens, whose work is published by the University of Alaska Fairbanks and the Alaska Energy Authority.
 <br> <br>
These datasets will be further described in step one of the notebook.

##Approach
First, we need to retrieve the data from the different sources: <br>
1) RODEO FeatureCollection - Alaska <br>
2) Alaska Energy Authority Library - In River Potential <br> <br>
Note: This process was a bit tedious and requires local data management. However, if you reach out to Logan Borger at ltborger@alaska.edu, he can send the you the cleaned files.<br> <br>
Second, we create a unified dataset by correlating the data according to the proximity of latitude and longitude coordinates. <br> <br>
Third, we seek to establish the relationships between Location, Width, Discharge, and Power Density (Potential) by looking at the river features associated with different Power Density (Potential) ratings. Here we apply an ANOVA test to the findings in order to validate significance of the relationships. Additionally, Tukey's HSD (Honestly Significant Difference) is applied.  <br> <br>
Fourth, we establish a 25% threshold for a minimum Width and Discharge to be associated with both "Good" and "Great" Potential ratings. Applying this threshold to the larger dataset shows that there are a number of locations that show similar river features to "Good" and "Great" potential locations, but are not considered so.

##Summary of Findings

1. RODEO data is capable of predicting power density at different locations.
2. Rivers with larger Discharge and Width have less power density than smaller rivers.
3. There are some outliers in the data, such as Aniak, that return data from offshoots of the main river and fail to capture the true Potential of a location.

# 1. Retrieve the Data

##Retrieving the RODEO Data

The RODEO Data is currently in the form of a FeatureCollection in Google Earth Engine. We are going to export the FeatureCollection to Google Drive, clean it, and create a DataFrame from the data.  <br>  <br>
Note: Asking for the files will simplify this process, as there is no code to clean the file. You'll simply need to input the path to the data in your Google Drive to run the code.

First, we need to log into Earth Engine and Initialize the project.  <br> <br>

Enter your project path, which will be associated with your Google Earth Engine Account. <br> It will be of the form: 'ee-my-username'
"""

project_path ='ee-my-loganborger' #@param {type:"string"}

# Import packages and login to EE
import pandas as pd
import geemap
import ee

ee.Authenticate()
ee.Initialize(project= project_path )

"""Second, we need to mount the drive in order to retrieve the FeatureCollection data we will export from Google Earth Engine to Google Drive."""

# Import drive package and mount it
from google.colab import drive
drive.mount('/content/drive',force_remount=True)

"""Third, we need to export the data from GEE. You'll need to ingest the FeatureCollection shapefile as an asset and copy the path to it. After you run the code below, you'll need to go to your GEE console and run the task. This will export the csv to your Google Drive. The csv will need to be cleaned before moving on. This which mainly involves pulling out the Latitude and Longitude into their own columns. <br> <br>

Note: This can be skipped if you have the cleaned data in your Google Drive.
"""

asset_path = "projects/ee-my-loganborger/assets/RODEO_shp" #@param {type:"string"}

# Export data from GEE
#task = ee.batch.Export.table.toDrive(ee.FeatureCollection(asset_path))
#task.start()

"""Fourth, we are going to create a dataframe from the .csv file created."""

rodeo_cleaned_path = "/content/drive/MyDrive/RODEO_Analysis/RODEO_Data_Cleaned.csv" #@param {type:"string"}

# making dataframe
rodeo_df = pd.read_csv(rodeo_cleaned_path)

# output the dataframe
print(rodeo_df)

"""Fifth, we convert the values to numeric values for future analysis."""

import numpy as np

# Convert RODEO features to numeric values - np.float64
rodeo_df['id'] = rodeo_df['id'].astype(np.float64)
rodeo_df['Latitude'] = rodeo_df['Latitude'].astype(np.float64)
rodeo_df['Longitude'] = rodeo_df['Longitude'].astype(np.float64)
rodeo_df['Date'] = rodeo_df['Date'].astype(np.float64)
rodeo_df['Q'] = rodeo_df['Q'].astype(np.float64)
rodeo_df['Width'] = rodeo_df['Width'].astype(np.float64)

"""##RODEO Data Description

Overview: The RODEO (Remotely Observed Discharge from Effective width Occurrence)  Dataset is produced by an algorithm that characterizes Discharge and Width of river in North America from LandSat observations.
<br> <br>
Read more here: https://www.sciencedirect.com/science/article/pii/S1364815221002966

##Visualization
"""

# Import the shapefile as a FeatureCollection
shapefile_fc = ee.FeatureCollection(asset_path)

#Visualization of Shapefile
from geemap import Map

map = Map()

# Add the shapefile to the map
map.addLayer(shapefile_fc, {}, 'RODEO')

# Center the map on the shapefile
map.centerObject(shapefile_fc, 4)

# Display the map
map

"""## Description of Retrieved RODEO DataFrame

Note: The RODEO data utilized in this notebook corresponds to periods with cloud cover below the recommended threshold of 10%. It includes 317, 781 rows of data corresponding to the parameters defined below.

**id**: This is the reference number associated with a timeseries of Discharge and Width measurements at a specific location. There are 4009 unique ids for the state of Alaska and are characterized by the points on the visualization.

**Latitude**: This is the Latitude value that corresponds to the id location.

**Longitude**: This is the Longitude value that corresponds to the id location.

**Date**: This corresponds to the date in which the discharge and width were collected at a certain id. This time is in epoch units.

**Q**: This is the measurement of the discharge of the river. This corresponds to the amount of water passing through a cross-section of the river at a given point in time. This is estimated by RODEO in units of cubic meters per second.

**Width**: This is the measurement of the width of a river at an id location at a given point in time. This is estimated by RODEO in units of meters.
"""

# Identify the number of unique ids
rodeo_df['id'].nunique()

# Characterize the RODEO data by id in terms of Width and Discharge
summary = rodeo_df.groupby('id')[['Width', 'Q']].describe()

summary

"""Next, we can visualize the distribution of Width and Discharge for the various ids."""

# Import sns and matplotlib.pyplot packages
import seaborn as sns
import matplotlib.pyplot as plt

# Set the style
sns.set_style("whitegrid")

# Set up the figure and axes
fig, ax = plt.subplots(2, 1, figsize=(15, 12))

# Boxplot for Width
sns.boxplot(data=rodeo_df, x='id', y='Width', ax=ax[0])
ax[0].set_title('Distribution of Width by ID')
ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=45, ha='right')

# Boxplot for Discharge
sns.boxplot(data=rodeo_df, x='id', y='Q', ax=ax[1])
ax[1].set_title('Distribution of Discharge by ID')
ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=45, ha='right')

#plt.tight_layout()
plt.show()

"""##Retrieve the In-River Potential Data

This data has to be manually compiled in excel from [here](https://www.arcgis.com/apps/mapviewer/index.html?layers=b122b04ec1e64ed08ada789f840c4379&layerId=3). This should include the FID, the Location, Potential, Latitude, and Longitude. <br> <br>
Note: You can ask for this file and expedite the process.
"""

inriver_path = "/content/drive/MyDrive/RODEO_Analysis/InRiver_Potential_Data.csv" #@param {type:"string"}

# making dataframe
inriver_data = pd.read_csv(inriver_path)

# output the dataframe
print(inriver_data)

"""##In-River Potential Data Description

The University of Alaska Anchorage (UAA) conducted a statewide assessment of the in-river
hydrokinetic energy resources in Alaska. This included 26 rural villages/locations in which Acoustic Doppler Current Profiler (ADCP) surveys of river segments were conducted. This assessment included surveys of bathymetry, topography, velocity, and water
surface elevation. Hydrologic models were developed based upon the data and were used to estimate the hydrokinetic power density (W/m2) at the 25, 50, and 75-percentile flow rates of the open water period at each village site (Ravens, 2014).

Note: There is a distinction to be made between hydrokinetic power density and hydrokinetic potential.

**FID**: This is the reference number associated with a certain Location, Potential, Latitude, and Longitude.

**Location**: This is the name of the rural village in which the assessment was made.

**Potential**: This is the a rating produced from the hydrokinetic power density (W/m^2) estimates by Ravens. Each site was designated a rating. <br>

**Latitude**: This is the Latitude value that corresponds to the village location.

**Longitude**: This is the Longitude value that corresponds to the village location.

##Potential Rating Definition
 These qualitative rating categories have been carried over from the In-River Potential Dataset. <br><br>



Potential Rating Categories:<br>
Lowest: 50-220 W/m^<br>
Low: 220-450 W/m^2 <br>
Good: 600-900 W/m^2<br>
Great: 1500-1700 W/m^2

# 2. Unify the Datasets

Essentially, the datasets are able to be unified because they both have Latitude and Longitude values. We are going to pull out the coordinates from the In-River data and filter out rows of RODEO data that fall within a buffer area (0.04, ~4km). Then, we are going to add columns to define the central locations and the determined potential.  <br>

First, we need to extract the Location, Potential, Latitude, and Longitude values from the In-River data.
"""

# Extract Location Names
location_list = []

for i in range (0, len(inriver_data)):
  store_02 =  inriver_data.loc[i]
  location_list.append(store_02["Location"])

print(location_list)

# Extract Potential
potential_list = []

for i in range (0, len(inriver_data)):
  store_02 =  inriver_data.loc[i]
  potential_list.append(store_02["Potential"])

print(potential_list)

# Extract Lat/Long
dict_list_lat = []
dict_list_long = []

for i in range (0, len(inriver_data)):
  store_01 =  inriver_data.loc[i]
  dict_list_lat.append(float(store_01["Latitude"]))
  dict_list_long.append(float(store_01["Longitude"]))

print(dict_list_lat)
print(type(dict_list_long[0]))

"""Next, we pull out RODEO data from the desired buffer region."""

buffer_in_km = "7" #@param {type:"string"}
buffer_in_km = float(buffer_in_km)

# Buffer Correction
import math

def get_lat_long_buffer(lat, buffer): # buffer size in km

  lat_degrees = buffer/111.32
  long_degrees = (buffer *360)/(40075*math.cos(math.radians(lat)))

  return((lat_degrees, long_degrees))

buffers_lat_long = []

for i in range(0, len(inriver_data)):
  lat_degrees, long_degrees = get_lat_long_buffer(dict_list_lat[i], buffer_in_km)
  buffers_lat_long.append(rodeo_df.loc[(rodeo_df['Latitude']> dict_list_lat[i]-lat_degrees)&(rodeo_df['Latitude']<dict_list_lat[i]+lat_degrees)&(rodeo_df['Longitude']>dict_list_long[i]-long_degrees)&(rodeo_df['Longitude']<dict_list_long[i]+long_degrees)])

print(buffers_lat_long)

"""Now, we define a function to add a column with a name to the dataframe and we add the location names. <br> <br>
Note: If you get an error saying you cannot add a name because one already exists, you will need to run the cell above this block first.
"""

# function to add name colmn to dataframe
def addNameColumn(dataframe, name):
  namelst = []
  for i in range(0, len(dataframe)):
    namelst.append(name)

  # print(namelst)
  new_column = {'newCol': namelst}
  df2 = pd.DataFrame(new_column)
  dataframe = dataframe.insert(0, 'Location', namelst)
  return dataframe

# apply the function to buffers_lat_long
for i, df in enumerate(buffers_lat_long):
  addNameColumn(df, location_list[i])

print(buffers_lat_long)

"""Here, we redefine the function to add a column with a name to the dataframe, but with different parameters. This adds the potential to the dataframe."""

def addNameColumn(dataframe, name):
  namelst = []
  for i in range(0, len(dataframe)):
    namelst.append(name)

  # print(namelst)
  new_column = {'newCol': namelst}
  df2 = pd.DataFrame(new_column)
  dataframe = dataframe.insert(0, 'Potential', namelst)
  return dataframe

# apply the function to buffers_lat_long
for i, df in enumerate(buffers_lat_long):
  addNameColumn(df, potential_list[i])

print(buffers_lat_long)

"""Next, we produce summary of the statistics associated with each location."""

summary_stats_list = []  # Initialize an empty list to store summary stats for each DataFrame

for i in range(0, len(buffers_lat_long)):
    if not buffers_lat_long[i].empty:  # Check if the DataFrame is not empty
        summary_stats = buffers_lat_long[i].groupby('Location')[['id', 'Width', 'Q']].describe()
        summary_stats_list.append(summary_stats)  # Append summary stats to the list

# Concatenate summary stats from all DataFrames in the list
combined_summary_stats = pd.concat(summary_stats_list)

print(combined_summary_stats)

"""Finally, we combine the dataframes."""

# Concatenate the list of DataFrames into a single DataFrame
combined_df = pd.concat(buffers_lat_long, ignore_index=True)

print(combined_df)

"""We can now plot the distribution of Width and Discharge values for each location."""

import seaborn as sns
import matplotlib.pyplot as plt

# Set the style
sns.set_style("whitegrid")

# Set up the figure and axes
fig, ax = plt.subplots(2, 1, figsize=(15, 12))

# Boxplot for Effective_width
sns.boxplot(data=combined_df, x='Location', y='Width', palette = sns.color_palette("pastel"), legend=False, ax=ax[0])
ax[0].set_title('Distribution of Width by Sites')
ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=45, ha='right')

# Boxplot for Discharge
sns.boxplot(data=combined_df, x='Location', y='Q', palette = sns.color_palette("pastel"), legend=False, ax=ax[1])
ax[1].set_title('Distribution of Discharge by Sites')
ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=45, ha='right')

plt.tight_layout()
plt.show()

"""We can also plot the relationship between Width and Discharge for each of the Sites.
<br> <br>
Note: Aniak (in red) is an outlier as the buffer, in this case, is picking up a stream rather than the main river due to no RODEO points existing within the 4 km buffer.
"""

# Scatter plot for Width vs Discharge
plt.figure(figsize=(15, 10))
sns.scatterplot(data=combined_df, x='Width', y='Q', hue='Location', palette='tab20', edgecolor=None, s=50)
plt.title('Relationship between Width and Discharge')
plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
plt.tight_layout()
plt.show()

"""#3. Establish Relationship between **Location**, **Width**, **Discharge** and **Potential**

This section seeks to establish and provide basic insights into the relationship between Location, Width, Discharge, and Potential. <br>


First we summarize the statistics for Width and Discharge grouped by Potential to get an understanding of how these metrics vary for different potential ratings.
"""

# Calculate summary statistics for 'Effective_width' and 'Discharge' grouped by 'Potential'
potential_stats = combined_df.groupby('Potential')[['Width', 'Q']].describe()

potential_stats

"""Next, we plot several boxplots for Width and Discharge separated by Potential to visualize the distribution of these variables for each potential rating. Then we create a scatter plot with Width on the x-axis, Discharge on the y-axis, colored by Potential to visualize the relationship between these metrics and hydrokinetic potential."""

# Set up the figure and axes
fig, ax = plt.subplots(2, 1, figsize=(12, 10))

# Boxplot for Effective_width by Potential
sns.boxplot(data=combined_df, x='Potential', y='Width', order=['Lowest', 'Low', 'Good', 'Great'], ax=ax[0])
ax[0].set_title('Distribution of Effective_width by Potential')

# Boxplot for Discharge by Potential
sns.boxplot(data=combined_df, x='Potential', y='Q', order=['Lowest', 'Low', 'Good', 'Great'], ax=ax[1])
ax[1].set_title('Distribution of Discharge by Potential')

plt.tight_layout()
plt.show()

# Scatter plot for Effective_width vs Discharge colored by Potential
plt.figure(figsize=(15, 10))
sns.scatterplot(data=combined_df, x='Width', y='Q', hue='Potential',
                hue_order=['Lowest', 'Low', 'Good', 'Great'], edgecolor=None, s=50, palette='viridis')
plt.title('Relationship between Width and Discharge by Potential')
plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
plt.tight_layout()
plt.show()

"""Finally, we can employ an ANOVA test to determine if there is a significant difference in Width and Discharge among different Potential rating categories."""

import scipy.stats as stats

# Perform one-way ANOVA for Effective_width against Potential
f_statistic_width, p_value_width = stats.f_oneway(
    combined_df['Width'][combined_df['Potential'] == 'Lowest'],
    combined_df['Width'][combined_df['Potential'] == 'Low'],
    combined_df['Width'][combined_df['Potential'] == 'Good'],
    combined_df['Width'][combined_df['Potential'] == 'Great']
)

float(f_statistic_width),float(p_value_width)

"""For the ANOVA analysis on Width against Potential:

F-statistic:
513.68

P-value:
0.0


Given the extremely low p-value (essentially zero), we can conclude that there is a statistically significant difference in the mean Width across the different levels of Potential.
"""

# Perform one-way ANOVA for Discharge against Potential
f_statistic_discharge, p_value_discharge = stats.f_oneway(
    combined_df['Q'][combined_df['Potential'] == 'Lowest'],
    combined_df['Q'][combined_df['Potential'] == 'Low'],
    combined_df['Q'][combined_df['Potential'] == 'Good'],
    combined_df['Q'][combined_df['Potential'] == 'Great']
)

float(f_statistic_discharge), float(p_value_discharge)

"""For the ANOVA analysis on Discharge against Potential:

F-statistic:
760.46

P-value:
0.0

Similar to the results for Width, the extremely low p-value for Discharge indicates that there is a statistically significant difference in the mean Discharge across the different levels of Potential.

## Post-hoc tests

After observing significant differences within the ANOVA test results, post-hoc tests are used to determine which specific groups differ from one another. The Tukey's HSD (Honestly Significant Difference) test is one of the most commonly used post-hoc tests following ANOVA. It compares all possible pairs of means while controlling the family-wise error rate.

We'll perform Tukey's HSD test for both Width and Discharge to determine which levels of Potential have significantly different means. <br><br>

First, we will look at the significance of differences in Potential categories based upon the mean Width categorical differences.
"""

from statsmodels.stats.multicomp import pairwise_tukeyhsd

# Post-hoc analysis for Effective_width
tukey_width = pairwise_tukeyhsd(endog=combined_df['Width'],
                                groups=combined_df['Potential'],
                                alpha=0.05)

# Convert the result to a DataFrame for better display
tukey_width_df = pd.DataFrame(data=tukey_width._results_table.data[1:], columns=tukey_width._results_table.data[0])

tukey_width_df

"""##HSD Test Description

The columns group1 and group2 represent the pair of Potential levels being compared.
meandiff is the difference in means between the two groups.
p-adj is the adjusted p-value for that pairwise comparison.
lower and upper are the lower and upper bounds of the 95% confidence interval for the mean difference.
reject indicates whether we should reject the null hypothesis for that pairwise comparison (i.e., if True, there's a significant difference between the groups).

All pairwise comparisons have a reject value of True, indicating that the mean Effective_width is significantly different between each pair of Potential levels.

Now, we will look at the significance of differences in Potential categories based upon the mean Discharge categorical differences.
"""

# Post-hoc analysis for Discharge
tukey_discharge = pairwise_tukeyhsd(endog=combined_df['Q'],
                                    groups=combined_df['Potential'],
                                    alpha=0.05)

# Convert the result to a DataFrame for better display
tukey_discharge_df = pd.DataFrame(data=tukey_discharge._results_table.data[1:], columns=tukey_discharge._results_table.data[0])

tukey_discharge_df

"""##Analysis of the Results

There's a significant difference in means between most pairs of Potential levels.

Notably, the Good and Great potential levels do not have a statistically significant difference in their mean discharges (with a p-adj value of 1.0 and a reject value of False).

In summary:

For both Width and Discharge, there are significant differences in means across the various hydrokinetic potential levels. However, categorical differences between Good and Great potential levels are insignificant when considering differences in mean Discharge .

#4. Determine and Apply Minimum Width and Discharge Thresholds for "Good" Potential to All Locations

## Minimum **Width** and **Discharge** to consistently expect *Great/Good* **Potential**

1. The minimum value (which represents the smallest observed value).

2. The 25th percentile (the value below which 25% of the observations lie) to get an idea of a consistent threshold, as this would exclude potential outliers.
"""

# Extract statistics for rows where Potential is "Great"
great_stats = combined_df[combined_df['Potential'] == 'Great'][['Width', 'Q']].describe()

# Extract minimum and 25th percentile for both Effective_width and Discharge
min_width_great = great_stats.loc['min', 'Width']
percentile_25_width_great = great_stats.loc['25%', 'Width']

min_discharge_great = great_stats.loc['min', 'Q']
percentile_25_discharge_great = great_stats.loc['25%', 'Q']

float(min_width_great),float(percentile_25_width_great),float(min_discharge_great), float(percentile_25_discharge_great)

great_stats

"""For sites with "Great" potential:

The minimum observed Width is
43.69 m. However, to account for potential outliers and to identify a more consistent threshold, the 25th percentile value for Width is
161.21 m. This means that about 25% of the sites with "Great" potential have n Width below this threshold.

The minimum observed Discharge is
10.72 cms. However, to account for potential outliers and to identify a more consistent threshold, the 25th percentile value for Discharge is
209.56 cms. This suggests that about 25% of the sites with "Great" potential have a Discharge below this value.

Thus, to consistently expect a "Great" potential, it might be more reliable to consider sites with a Width greater than or around
161.21 m and a Discharge greater than or around
209.56 cms, based on the current dataset.
"""

# Extract statistics for rows where Potential is "Good"
good_stats = combined_df[combined_df['Potential'] == 'Good'][['Width', 'Q']].describe()

# Extract minimum and 25th percentile for both Effective_width and Discharge
min_width_good = good_stats.loc['min', 'Width']
percentile_25_width_good = good_stats.loc['25%', 'Width']

min_discharge_good = good_stats.loc['min', 'Q']
percentile_25_discharge_good = good_stats.loc['25%', 'Q']

float(min_width_good), float(percentile_25_width_good), float(min_discharge_good), float(percentile_25_discharge_good)

"""For sites with "Good" potential:

The minimum observed Width is
0.55 m. However, to account for potential outliers and to identify a more consistent threshold, the 25th percentile value for Width is
122.93 m. This means that about 25% of the sites with "Good" potential have a Width below this threshold.

The minimum observed Discharge is
148.07 cms. The 25th percentile value for Discharge is
350.77 cms, suggesting that about 25% of the sites with "Good" potential have a Discharge below this value.

Thus, to consistently expect a "Good" potential, it might be more reliable to consider sites with a Width greater than or around
122.93 m and a Discharge greater than or around
350.77 cms, based on the current dataset.

## Other sites with these characteristics which do not have *Great* **Potential**

To identify sites with characteristics similar to those with "Great" potential but that do not have the "Great" potential label, we'll apply the following criteria based on the 25th percentile values we derived:

1. Width greater than or around 161.21 m.

2. Discharge greater than or around 209.56 cms.

3. Potential is not "Great".
"""

# Filter sites based on the derived criteria
similar_sites = combined_df[
    (combined_df['Width'] >= 161.21) &
    (combined_df['Q'] >= 209.56) &
    (combined_df['Potential'] != 'Great')
]

print(similar_sites[['Location', 'Width', 'Q', 'Potential']])
print(similar_sites.Location.unique())

"""There are 4345 observations in the dataset where sites exhibit characteristics similar to those with "Great" potential but do not have the "Great" potential label. These are comprised from observations specifically at Grayling, Holy Cross, Kaltag, Koyokuk, Marshall, Nulato, Chuathbaluk, Crooked Creek, Upper Kalskag, Napaimute, Red Devil, Sleetmute, and Whitestone.

## Other sites with these characteristics which do not have *Good/Great* **Potential**

To identify sites with characteristics similar to those with "Good" potential but that do not have the "Good/Great" potential label, we'll apply the following criteria based on the 25th percentile values we derived:

1. Width greater than or around 122.93 m.

2. Discharge greater than or around 350.77 cms.

3. Potential is not "Good".
"""

# Filter sites based on the derived criteria
similar_sites_2 = combined_df[
    (combined_df['Width'] >= 122.93) &
    (combined_df['Q'] >= 350.77) &
    (combined_df['Potential'] != 'Good') &
    (combined_df['Potential'] != 'Great')
]

print(similar_sites_2[['Location', 'Width', 'Q', 'Potential']])
print(similar_sites_2.Location.unique())

"""There are 4242 observations in the dataset where sites exhibit characteristics similar to those with "Good" potential but not considered "Good" or "Great". These are comprised from observations specifically at Grayling, Holy Cross, Kaltag, Koyokuk, Marshall, Nulato, Chuathbaluk, Crooked Creek, Upper Kalskag, Napaimute, Red Devil, Sleetmute, and Stony River.

#Assess Additional Communities

The established relationship can be applied to the rest of the Alaskan villages to characterize their potential.
"""

# making dataframe
additional_village_locations = pd.read_csv("/content/drive/MyDrive/RODEO_Analysis/Village_Location.csv")

# Convert 'Population' column to float, setting errors='coerce' to handle non-numeric values
additional_village_locations['Population'] = pd.to_numeric(additional_village_locations['Population'], errors='coerce')

# Drop rows where 'Population' is NaN
additional_village_locations = additional_village_locations.dropna(subset=['Population'])

# Filter the DataFrame to include only rows where 'Population' > 0
filtered_village_location = additional_village_locations[additional_village_locations['Population'] > 0]

# Print the new DataFrame
print(filtered_village_location)

filtered_village_location

# Extract Location Names
village_location_list = []

# Reset the index of the filtered DataFrame
filtered_village_location = filtered_village_location.reset_index(drop=True)

for i in range (0, len(filtered_village_location)):
  store_03 =  filtered_village_location.loc[i]
  village_location_list.append(store_03["Location"])

print(village_location_list)

# Extract Population
village_population_list = []

for i in range (0, len(filtered_village_location)):
  store_02 =  filtered_village_location.loc[i]
  village_population_list.append(int(store_02["Population"])) # Convert to standard integer

print(village_population_list)
print(type(village_population_list[0]))

# Extract Lat/Long
village_dict_list_lat = []
village_dict_list_long = []

for i in range (0, len(filtered_village_location)):
  store_01 =  filtered_village_location.loc[i]
  village_dict_list_lat.append(float(store_01["Latitude"]))
  village_dict_list_long.append(float(store_01["Longitude"]))

print(village_dict_list_lat)
print(type(village_dict_list_long[0]))

"""Next, we pull out RODEO data from the desired buffer region."""

buffer_in_km = "7" #@param {type:"string"}
buffer_in_km = float(buffer_in_km)

# Buffer Correction
import math

def get_lat_long_buffer(lat, buffer): # buffer size in km

  lat_degrees = buffer/111.32
  long_degrees = (buffer *360)/(40075*math.cos(math.radians(lat)))

  return((lat_degrees, long_degrees))

village_buffers_lat_long = []

for i in range(0, len(filtered_village_location)):
  lat_degrees, long_degrees = get_lat_long_buffer(village_dict_list_lat[i], buffer_in_km)
  buffered_data = rodeo_df.loc[(rodeo_df['Latitude']> village_dict_list_lat[i]-lat_degrees)&(rodeo_df['Latitude']<village_dict_list_lat[i]+lat_degrees)&(rodeo_df['Longitude']>village_dict_list_long[i]-long_degrees)&(rodeo_df['Longitude']<village_dict_list_long[i]+long_degrees)]
  if not buffered_data.empty: # Add this check to only append non-empty dataframes
    village_buffers_lat_long.append(buffered_data)

print(village_buffers_lat_long)

"""Now, we define a function to add a column with a name to the dataframe and we add the location names. <br> <br>
Note: If you get an error saying you cannot add a name because one already exists, you will need to run the cell above this block first.
"""

# function to add name colmn to dataframe
def addNameColumn(dataframe, name):
  namelst = []
  for i in range(0, len(dataframe)):
    namelst.append(name)

  # print(namelst)
  new_column = {'newCol': namelst}
  df2 = pd.DataFrame(new_column)
  dataframe = dataframe.insert(0, 'Location', namelst)
  return dataframe

# apply the function to buffers_lat_long
for i, df in enumerate(village_buffers_lat_long):
  addNameColumn(df, village_location_list[i])

print(village_buffers_lat_long)

"""Here, we redefine the function to add a column with a name to the dataframe, but with different parameters. This adds the population to the dataframe."""

def addNameColumn(dataframe, name):
  namelst = []
  for i in range(0, len(dataframe)):
    namelst.append(name)

  # print(namelst)
  new_column = {'newCol': namelst}
  df2 = pd.DataFrame(new_column)
  dataframe = dataframe.insert(0, 'Population', namelst)
  return dataframe

# apply the function to buffers_lat_long
for i, df in enumerate(village_buffers_lat_long):
  addNameColumn(df, village_population_list[i])

print(village_buffers_lat_long)

"""Next, we produce summary of the statistics associated with each location."""

summary_stats_list = []  # Initialize an empty list to store summary stats for each DataFrame

for i in range(0, len(village_buffers_lat_long)):
    if not village_buffers_lat_long[i].empty:  # Check if the DataFrame is not empty
        summary_stats = village_buffers_lat_long[i].groupby('Location')[['id', 'Width', 'Q']].describe()
        summary_stats_list.append(summary_stats)  # Append summary stats to the list

# Concatenate summary stats from all DataFrames in the list
combined_summary_stats = pd.concat(summary_stats_list)

print(combined_summary_stats)

"""Finally, we combine the dataframes."""

# Concatenate the list of DataFrames into a single DataFrame
combined_village_df = pd.concat(village_buffers_lat_long, ignore_index=True)

print(combined_village_df)

potential_stats

"""# Work in Progress
Analyze the `combined_village_df` and categorize each village's potential ('Lowest', 'Low', 'Good', 'Great') based on its average width and discharge relative to the thresholds defined in the `potential_stats` DataFrame. Create a new DataFrame containing the 'Location', assigned 'Potential', average 'Width', and average 'Q' for each village.

## Calculate average width and discharge for each village

### Subtask:
Group the `combined_village_df` by 'Location' and calculate the mean 'Width' and 'Q' for each village.

**Reasoning**:
The subtask is to group the combined_village_df by 'Location' and calculate the mean of 'Width' and 'Q' for each location. This can be achieved by using the `groupby()` method and the `mean()` aggregation function in pandas.
"""

# Group by 'Location' and calculate the mean of 'Width' and 'Q'
village_avg_features = combined_village_df.groupby('Location')[['Width', 'Q']].mean()

# Display the resulting DataFrame
display(village_avg_features)

"""## Define potential thresholds

### Subtask:
Extract the mean Width and Discharge values for each potential category ('Lowest', 'Low', 'Good', 'Great') from the `potential_stats` DataFrame.

**Reasoning**:
Extract the mean Width and Discharge for each potential category from the potential_stats DataFrame.
"""

mean_width_good = potential_stats.loc['Good', 'Width']['mean']
mean_discharge_good = potential_stats.loc['Good', 'Q']['mean']

mean_width_great = potential_stats.loc['Great', 'Width']['mean']
mean_discharge_great = potential_stats.loc['Great', 'Q']['mean']

mean_width_low = potential_stats.loc['Low', 'Width']['mean']
mean_discharge_low = potential_stats.loc['Low', 'Q']['mean']

mean_width_lowest = potential_stats.loc['Lowest', 'Width']['mean']
mean_discharge_lowest = potential_stats.loc['Lowest', 'Q']['mean']

print(f"Mean Width (Good): {mean_width_good}")
print(f"Mean Discharge (Good): {mean_discharge_good}")
print(f"Mean Width (Great): {mean_width_great}")
print(f"Mean Discharge (Great): {mean_discharge_great}")
print(f"Mean Width (Low): {mean_width_low}")
print(f"Mean Discharge (Low): {mean_discharge_low}")
print(f"Mean Width (Lowest): {mean_width_lowest}")
print(f"Mean Discharge (Lowest): {mean_discharge_lowest}")

"""## Categorize villages based on thresholds

### Subtask:
Categorize villages based on their average width and discharge relative to the defined potential thresholds.

**Reasoning**:
Define a function to categorize village potential based on average width and discharge relative to the mean thresholds, and apply it to the village features dataframe.
"""

def categorize_potential(row):
    # Categorize based on the inverse relationship observed
    if row['Width'] <= mean_width_great and row['Q'] <= mean_discharge_great:
        return 'Great'
    elif row['Width'] <= mean_width_good and row['Q'] <= mean_discharge_good:
        return 'Good'
    elif row['Width'] <= mean_width_low and row['Q'] <= mean_discharge_low:
        return 'Low'
    else:
        return 'Lowest'

# Apply the function to the village_avg_features DataFrame
village_avg_features['Assigned Potential'] = village_avg_features.apply(categorize_potential, axis=1)

pd.set_option('display.max_rows', None)
# Display the updated DataFrame
display(village_avg_features)

"""## Create final dataframe

### Subtask:
Construct a new DataFrame containing the 'Location', assigned 'Potential', average 'Width', and average 'Q' for each village.

**Reasoning**:
Construct a new DataFrame containing the 'Location', assigned 'Potential', average 'Width', and average 'Q' for each village.
"""

# Create a new DataFrame with selected columns
final_village_potential = village_avg_features[['Assigned Potential', 'Width', 'Q']]

# Display the new DataFrame
display(final_village_potential)

"""## Display the final dataframe

### Subtask:
Display the final dataframe containing the assigned potential and average river features for each village.

**Reasoning**:
Display the final dataframe containing the assigned potential and average river features for each village.
"""

print(final_village_potential)

"""## Summary:

### Data Analysis Key Findings

* The average width and discharge were calculated for each of the 124 villages in the dataset.
* The threshold values for classifying villages into 'Lowest', 'Low', 'Good', and 'Great' potential categories were successfully extracted from the `potential_stats` DataFrame.
* Each village was assigned a potential category based on its average width and discharge relative to the established thresholds.
* A final DataFrame was created, presenting the 'Location' of each village along with its assigned 'Potential', average 'Width', and average 'Q'.

### Insights or Next Steps

* The resulting DataFrame provides a clear categorization of villages based on their river characteristics, which can be used to prioritize locations for potential river-related projects or interventions.
* Further analysis could involve exploring the distribution of villages across the different potential categories and investigating other factors that might influence a village's potential.

## Create final dataframe

### Subtask:
Construct a new DataFrame containing the 'Location', assigned 'Potential', average 'Width', and average 'Q' for each village.

**Reasoning**:
Construct a new DataFrame containing the 'Location', assigned 'Potential', average 'Width', and average 'Q' for each village.
"""

# Create a new DataFrame with selected columns
final_village_potential = village_avg_features[['Assigned Potential', 'Width', 'Q']]

# Display the new DataFrame
display(final_village_potential)

"""## Display the final dataframe

### Subtask:
Display the final dataframe containing the assigned potential and average river features for each village.

**Reasoning**:
Display the final dataframe containing the assigned potential and average river features for each village.
"""

print(final_village_potential)

"""## Summary:

### Data Analysis Key Findings

* The average width and discharge were calculated for each of the 124 villages in the dataset.
* The threshold values for classifying villages into 'Lowest', 'Low', 'Good', and 'Great' potential categories were successfully extracted from the `potential_stats` DataFrame.
* Each village was assigned a potential category based on its average width and discharge relative to the established thresholds.
* A final DataFrame was created, presenting the 'Location' of each village along with its assigned 'Potential', average 'Width', and average 'Q'.

### Insights or Next Steps

* The resulting DataFrame provides a clear categorization of villages based on their river characteristics, which can be used to prioritize locations for potential river-related projects or interventions.
* Further analysis could involve exploring the distribution of villages across the different potential categories and investigating other factors that might influence a village's potential.
"""
